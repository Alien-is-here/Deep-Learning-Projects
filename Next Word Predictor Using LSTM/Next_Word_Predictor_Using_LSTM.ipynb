{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Djw-3IMa5vpf"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"\n",
        "What Is Pluto?\n",
        "Pluto is a dwarf planet, a Kuiper Belt object and a trans-Neptunian object.\n",
        "\n",
        "Clyde Tombaugh, a U.S. astronomer, discovered Pluto in 1930. That same year, Venetia Burney, an 11-year-old girl from England, suggested it be named “Pluto” after the Roman god of the dead.\n",
        "\n",
        "Pluto is a dwarf planet. A dwarf planet is round and orbits the sun just like the eight major planets of the solar system. A dwarf planet also is much smaller than a planet, but it is not a moon because a dwarf planet orbits the sun.\n",
        "\n",
        "On average, Pluto is a distance of 39.5 astronomical units, or AU, from the sun. That is almost 40 times farther from the sun than Earth is. Because of its elliptical orbit, Pluto is not the same distance from the sun all the time. Pluto’s closest point to the sun is 29.7 AU. Getting this close means that Pluto sometimes crosses Neptune’s path. Neptune is 30 AU from the sun. Pluto’s farthest point away from the sun is 49.3 AU. Pluto is in a region called the Kuiper (KY-per) Belt. The Kuiper Belt is a large donut of thousands of small, icy objects that orbit the sun beyond Neptune. What Is Pluto Like?\n",
        "It is very, very cold on Pluto. Scientists believe the temperature on Pluto is about minus 230 Celsius or minus 375 to minus 400 degrees Fahrenheit. It is 74 Celsius or 133 degrees Fahrenheit colder than the coldest temperature recorded in Antarctica. Pluto is so far away from Earth that scientists have known very little about what the surface is like until recently.\n",
        "\n",
        "Pluto has about one-fifteenth the gravity of Earth. That means a person who weighs 45 kilograms or 100 pounds on Earth would weigh 3 kilograms or about 7 pounds on Pluto.\n",
        "\n",
        "Most planets orbit the sun in a near-circle with the sun in the center. But Pluto’s orbit is an ellipse, and the sun is not in the center. Pluto’s orbit is also tilted compared to the orbits of the eight planets. The path on which Pluto orbits is angled 17 degrees above the line, or plane, where other planets orbit.\n",
        "\n",
        "How Is NASA Exploring Pluto?\n",
        "NASA has learned a lot about Pluto from studying images taken by the Hubble Space Telescope. Scientists used Hubble to take pictures of Pluto’s surface and to discover four of Pluto’s moons. But even though the telescope is powerful, Hubble’s images are fuzzy.\n",
        "\n",
        "NASA sent a flyby mission for a close-up look at Pluto. A flyby mission is one in which the spacecraft does not land or stay in orbit of the body it is studying. Instead, the spacecraft for this type of mission uses cameras to study its target as it flies past.\n",
        "\n",
        "NASA launched the piano-sized New Horizons spacecraft in January 2006 as the first mission to Pluto. New Horizons conducted a six-month flyby study of the dwarf planet in 2015. The spacecraft made its closest approach on July 14, 2015.\n",
        "\n",
        "New Horizons has cameras that took pictures of Pluto. The spacecraft also has scientific instruments that gathered information. From the cameras and other instruments on New Horizons, NASA has learned many new facts about Pluto.\n",
        "Scientists have learned that the dwarf planet is about two-thirds rock and one-third ice. They concluded this from studying the pictures taken by New Horizons and by measuring Pluto’s density. Other images show that Pluto may have ice volcanoes. Instead of spewing lava like volcanoes on Earth, these volcanoes probably emit a cold, slushy mixture of water ice, nitrogen, methane and other substances. Mountains are made of giant blocks of frozen water (ice). Plains look like they are made of a frozen gas, nitrogen.\n",
        "\n",
        "The mission has also shown us that Pluto’s moons are not like other moons. Most moons of the solar system always keep one face pointed toward the planets they orbit. Pluto’s four smaller moons spin so fast that they do not keep one face pointed to Pluto. Hydra spins fastest at 89 times for every orbit around Pluto! The smaller moons of Pluto also wobble much more than other moons. These moons wobble like spinning tops. Another difference between Pluto’s moons and other moons in the solar system is that it seems that at least two of Pluto’s moons were formed when two smaller, rocky bodies merged. So scientists believe that, at one time, Pluto had more than five moons.\n",
        "\n",
        "After finishing the study of Pluto and its moons, New Horizons is moving on to study objects deeper in the Kuiper Belt. One of those objects is called 2014 MU69, which is 40 to 50 kilometers (30 miles) wide and more than a billion miles beyond Pluto.Why Is NASA Exploring Pluto?\n",
        "Exploring planets is a historic endeavor and a major focus of NASA. Spacecraft have visited all eight planets in the solar system. NASA seeks to answer fundamental questions: How did our solar system form and evolve? Is there life beyond Earth? What are the hazards to life on Earth? Studying Kuiper Belt objects like Pluto may help scientists learn more about how planets form.\n",
        "\n",
        "NASA has several types of missions to study planets and other bodies in space: flybys, orbiting spacecraft, landers, and rovers. Sometimes NASA conducts a sample-return mission to bring rocks or soil from another body to Earth. Each type of mission helps advance human understanding of the chemical and physical history of the solar system.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "hjnmqv0KL1_y"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "6Ujw6VMvM5Tz"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "_P_kwseYNErT"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdM9z65wNb3y",
        "outputId": "fe14d45d-2d6d-4c76-d1d0-e11f4aac0826"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "346"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skm8_ixTNJnV",
        "outputId": "99075fd5-b096-454f-c401-59c5dcc1efb0"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'is': 2,\n",
              " 'pluto': 3,\n",
              " 'of': 4,\n",
              " 'a': 5,\n",
              " 'and': 6,\n",
              " 'that': 7,\n",
              " 'to': 8,\n",
              " 'in': 9,\n",
              " 'moons': 10,\n",
              " 'sun': 11,\n",
              " 'from': 12,\n",
              " 'on': 13,\n",
              " 'pluto’s': 14,\n",
              " 'nasa': 15,\n",
              " 'planets': 16,\n",
              " 'orbit': 17,\n",
              " 'planet': 18,\n",
              " 'like': 19,\n",
              " 'or': 20,\n",
              " 'earth': 21,\n",
              " 'about': 22,\n",
              " 'other': 23,\n",
              " 'dwarf': 24,\n",
              " 'it': 25,\n",
              " 'has': 26,\n",
              " 'one': 27,\n",
              " 'mission': 28,\n",
              " 'spacecraft': 29,\n",
              " 'new': 30,\n",
              " 'solar': 31,\n",
              " 'system': 32,\n",
              " 'than': 33,\n",
              " 'not': 34,\n",
              " 'scientists': 35,\n",
              " 'horizons': 36,\n",
              " 'kuiper': 37,\n",
              " 'belt': 38,\n",
              " 'also': 39,\n",
              " 'are': 40,\n",
              " 'study': 41,\n",
              " 'what': 42,\n",
              " 'orbits': 43,\n",
              " 'smaller': 44,\n",
              " 'au': 45,\n",
              " 'its': 46,\n",
              " 'objects': 47,\n",
              " 'have': 48,\n",
              " 'studying': 49,\n",
              " 'at': 50,\n",
              " 'ice': 51,\n",
              " 'they': 52,\n",
              " 'more': 53,\n",
              " 'eight': 54,\n",
              " 'but': 55,\n",
              " 'this': 56,\n",
              " 'beyond': 57,\n",
              " 'very': 58,\n",
              " 'minus': 59,\n",
              " 'degrees': 60,\n",
              " 'so': 61,\n",
              " 'which': 62,\n",
              " 'how': 63,\n",
              " 'exploring': 64,\n",
              " 'learned': 65,\n",
              " 'images': 66,\n",
              " 'by': 67,\n",
              " 'pictures': 68,\n",
              " 'flyby': 69,\n",
              " 'for': 70,\n",
              " 'cameras': 71,\n",
              " 'made': 72,\n",
              " 'two': 73,\n",
              " 'volcanoes': 74,\n",
              " 'object': 75,\n",
              " 'same': 76,\n",
              " 'year': 77,\n",
              " 'an': 78,\n",
              " 'after': 79,\n",
              " 'major': 80,\n",
              " 'much': 81,\n",
              " 'because': 82,\n",
              " 'distance': 83,\n",
              " '40': 84,\n",
              " 'times': 85,\n",
              " 'all': 86,\n",
              " 'time': 87,\n",
              " 'closest': 88,\n",
              " 'point': 89,\n",
              " '7': 90,\n",
              " 'close': 91,\n",
              " 'means': 92,\n",
              " 'sometimes': 93,\n",
              " 'path': 94,\n",
              " 'neptune': 95,\n",
              " '30': 96,\n",
              " 'away': 97,\n",
              " '3': 98,\n",
              " 'called': 99,\n",
              " 'cold': 100,\n",
              " 'believe': 101,\n",
              " 'temperature': 102,\n",
              " 'celsius': 103,\n",
              " 'fahrenheit': 104,\n",
              " 'surface': 105,\n",
              " 'kilograms': 106,\n",
              " 'pounds': 107,\n",
              " 'most': 108,\n",
              " 'center': 109,\n",
              " 'taken': 110,\n",
              " 'hubble': 111,\n",
              " 'space': 112,\n",
              " 'telescope': 113,\n",
              " 'four': 114,\n",
              " 'look': 115,\n",
              " 'body': 116,\n",
              " 'instead': 117,\n",
              " 'type': 118,\n",
              " 'as': 119,\n",
              " '2015': 120,\n",
              " 'instruments': 121,\n",
              " 'may': 122,\n",
              " 'these': 123,\n",
              " 'water': 124,\n",
              " 'nitrogen': 125,\n",
              " 'frozen': 126,\n",
              " 'keep': 127,\n",
              " 'face': 128,\n",
              " 'pointed': 129,\n",
              " 'wobble': 130,\n",
              " 'another': 131,\n",
              " 'bodies': 132,\n",
              " 'miles': 133,\n",
              " 'form': 134,\n",
              " 'life': 135,\n",
              " 'trans': 136,\n",
              " 'neptunian': 137,\n",
              " 'clyde': 138,\n",
              " 'tombaugh': 139,\n",
              " 'u': 140,\n",
              " 's': 141,\n",
              " 'astronomer': 142,\n",
              " 'discovered': 143,\n",
              " '1930': 144,\n",
              " 'venetia': 145,\n",
              " 'burney': 146,\n",
              " '11': 147,\n",
              " 'old': 148,\n",
              " 'girl': 149,\n",
              " 'england': 150,\n",
              " 'suggested': 151,\n",
              " 'be': 152,\n",
              " 'named': 153,\n",
              " '“pluto”': 154,\n",
              " 'roman': 155,\n",
              " 'god': 156,\n",
              " 'dead': 157,\n",
              " 'round': 158,\n",
              " 'just': 159,\n",
              " 'moon': 160,\n",
              " 'average': 161,\n",
              " '39': 162,\n",
              " '5': 163,\n",
              " 'astronomical': 164,\n",
              " 'units': 165,\n",
              " 'almost': 166,\n",
              " 'farther': 167,\n",
              " 'elliptical': 168,\n",
              " '29': 169,\n",
              " 'getting': 170,\n",
              " 'crosses': 171,\n",
              " 'neptune’s': 172,\n",
              " 'farthest': 173,\n",
              " '49': 174,\n",
              " 'region': 175,\n",
              " 'ky': 176,\n",
              " 'per': 177,\n",
              " 'large': 178,\n",
              " 'donut': 179,\n",
              " 'thousands': 180,\n",
              " 'small': 181,\n",
              " 'icy': 182,\n",
              " '230': 183,\n",
              " '375': 184,\n",
              " '400': 185,\n",
              " '74': 186,\n",
              " '133': 187,\n",
              " 'colder': 188,\n",
              " 'coldest': 189,\n",
              " 'recorded': 190,\n",
              " 'antarctica': 191,\n",
              " 'far': 192,\n",
              " 'known': 193,\n",
              " 'little': 194,\n",
              " 'until': 195,\n",
              " 'recently': 196,\n",
              " 'fifteenth': 197,\n",
              " 'gravity': 198,\n",
              " 'person': 199,\n",
              " 'who': 200,\n",
              " 'weighs': 201,\n",
              " '45': 202,\n",
              " '100': 203,\n",
              " 'would': 204,\n",
              " 'weigh': 205,\n",
              " 'near': 206,\n",
              " 'circle': 207,\n",
              " 'with': 208,\n",
              " 'ellipse': 209,\n",
              " 'tilted': 210,\n",
              " 'compared': 211,\n",
              " 'angled': 212,\n",
              " '17': 213,\n",
              " 'above': 214,\n",
              " 'line': 215,\n",
              " 'plane': 216,\n",
              " 'where': 217,\n",
              " 'lot': 218,\n",
              " 'used': 219,\n",
              " 'take': 220,\n",
              " 'discover': 221,\n",
              " 'even': 222,\n",
              " 'though': 223,\n",
              " 'powerful': 224,\n",
              " 'hubble’s': 225,\n",
              " 'fuzzy': 226,\n",
              " 'sent': 227,\n",
              " 'up': 228,\n",
              " 'does': 229,\n",
              " 'land': 230,\n",
              " 'stay': 231,\n",
              " 'uses': 232,\n",
              " 'target': 233,\n",
              " 'flies': 234,\n",
              " 'past': 235,\n",
              " 'launched': 236,\n",
              " 'piano': 237,\n",
              " 'sized': 238,\n",
              " 'january': 239,\n",
              " '2006': 240,\n",
              " 'first': 241,\n",
              " 'conducted': 242,\n",
              " 'six': 243,\n",
              " 'month': 244,\n",
              " 'approach': 245,\n",
              " 'july': 246,\n",
              " '14': 247,\n",
              " 'took': 248,\n",
              " 'scientific': 249,\n",
              " 'gathered': 250,\n",
              " 'information': 251,\n",
              " 'many': 252,\n",
              " 'facts': 253,\n",
              " 'thirds': 254,\n",
              " 'rock': 255,\n",
              " 'third': 256,\n",
              " 'concluded': 257,\n",
              " 'measuring': 258,\n",
              " 'density': 259,\n",
              " 'show': 260,\n",
              " 'spewing': 261,\n",
              " 'lava': 262,\n",
              " 'probably': 263,\n",
              " 'emit': 264,\n",
              " 'slushy': 265,\n",
              " 'mixture': 266,\n",
              " 'methane': 267,\n",
              " 'substances': 268,\n",
              " 'mountains': 269,\n",
              " 'giant': 270,\n",
              " 'blocks': 271,\n",
              " 'plains': 272,\n",
              " 'gas': 273,\n",
              " 'shown': 274,\n",
              " 'us': 275,\n",
              " 'always': 276,\n",
              " 'toward': 277,\n",
              " 'spin': 278,\n",
              " 'fast': 279,\n",
              " 'do': 280,\n",
              " 'hydra': 281,\n",
              " 'spins': 282,\n",
              " 'fastest': 283,\n",
              " '89': 284,\n",
              " 'every': 285,\n",
              " 'around': 286,\n",
              " 'spinning': 287,\n",
              " 'tops': 288,\n",
              " 'difference': 289,\n",
              " 'between': 290,\n",
              " 'seems': 291,\n",
              " 'least': 292,\n",
              " 'were': 293,\n",
              " 'formed': 294,\n",
              " 'when': 295,\n",
              " 'rocky': 296,\n",
              " 'merged': 297,\n",
              " 'had': 298,\n",
              " 'five': 299,\n",
              " 'finishing': 300,\n",
              " 'moving': 301,\n",
              " 'deeper': 302,\n",
              " 'those': 303,\n",
              " '2014': 304,\n",
              " 'mu69': 305,\n",
              " '50': 306,\n",
              " 'kilometers': 307,\n",
              " 'wide': 308,\n",
              " 'billion': 309,\n",
              " 'why': 310,\n",
              " 'historic': 311,\n",
              " 'endeavor': 312,\n",
              " 'focus': 313,\n",
              " 'visited': 314,\n",
              " 'seeks': 315,\n",
              " 'answer': 316,\n",
              " 'fundamental': 317,\n",
              " 'questions': 318,\n",
              " 'did': 319,\n",
              " 'our': 320,\n",
              " 'evolve': 321,\n",
              " 'there': 322,\n",
              " 'hazards': 323,\n",
              " 'help': 324,\n",
              " 'learn': 325,\n",
              " 'several': 326,\n",
              " 'types': 327,\n",
              " 'missions': 328,\n",
              " 'flybys': 329,\n",
              " 'orbiting': 330,\n",
              " 'landers': 331,\n",
              " 'rovers': 332,\n",
              " 'conducts': 333,\n",
              " 'sample': 334,\n",
              " 'return': 335,\n",
              " 'bring': 336,\n",
              " 'rocks': 337,\n",
              " 'soil': 338,\n",
              " 'each': 339,\n",
              " 'helps': 340,\n",
              " 'advance': 341,\n",
              " 'human': 342,\n",
              " 'understanding': 343,\n",
              " 'chemical': 344,\n",
              " 'physical': 345,\n",
              " 'history': 346}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3-1YHGONX44",
        "outputId": "210e8e55-663f-4246-e855-801757fda5ec"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "346"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "   tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "   for i in range(1, len(tokenized_sentence)):\n",
        "       input_sequences.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "eDqBzKZrNrA5"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input_sequences"
      ],
      "metadata": {
        "id": "xTI-t86oN0ul"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "5IH6lczg_FOU"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MklD2fRgNvLB",
        "outputId": "8e8ea9ce-7e99-4d37-f91d-a7f2d62962d5"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "L6wjfpKmBDv6"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ydN5SStFlZ2",
        "outputId": "625eae00-6eb1-4ec9-9253-1b8fbbace099"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  42,   2],\n",
              "       [  0,   0,   0, ...,  42,   2,   3],\n",
              "       [  0,   0,   0, ...,   0,   3,   2],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 346,   4,   1],\n",
              "       [  0,   0,   0, ...,   4,   1,  31],\n",
              "       [  0,   0,   0, ...,   1,  31,  32]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "QsOGr9oxF081"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences[:,:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ql0C6fZLKj8",
        "outputId": "c9cac6dc-f2ca-465a-dcfe-fd76ff511218"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,  42],\n",
              "       [  0,   0,   0, ...,   0,  42,   2],\n",
              "       [  0,   0,   0, ...,   0,   0,   3],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 345, 346,   4],\n",
              "       [  0,   0,   0, ..., 346,   4,   1],\n",
              "       [  0,   0,   0, ...,   4,   1,  31]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_sequences[:,-1]"
      ],
      "metadata": {
        "id": "gVMbmZ0DKZ0R"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences[:,-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x27CS0e4Kw64",
        "outputId": "fa74e625-d58f-46ae-bdba-792c94ed0aa3"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,   3,   2,   5,  24,  18,   5,  37,  38,  75,   6,   5, 136,\n",
              "       137,  75, 139,   5, 140, 141, 142, 143,   3,   9, 144,   7,  76,\n",
              "        77, 145, 146,  78, 147,  77, 148, 149,  12, 150, 151,  25, 152,\n",
              "       153, 154,  79,   1, 155, 156,   4,   1, 157,   2,   5,  24,  18,\n",
              "         5,  24,  18,   2, 158,   6,  43,   1,  11, 159,  19,   1,  54,\n",
              "        80,  16,   4,   1,  31,  32,   5,  24,  18,  39,   2,  81,  44,\n",
              "        33,   5,  18,  55,  25,   2,  34,   5, 160,  82,   5,  24,  18,\n",
              "        43,   1,  11, 161,   3,   2,   5,  83,   4, 162, 163, 164, 165,\n",
              "        20,  45,  12,   1,  11,   7,   2, 166,  84,  85, 167,  12,   1,\n",
              "        11,  33,  21,   2,  82,   4,  46, 168,  17,   3,   2,  34,   1,\n",
              "        76,  83,  12,   1,  11,  86,   1,  87,  14,  88,  89,   8,   1,\n",
              "        11,   2, 169,  90,  45, 170,  56,  91,  92,   7,   3,  93, 171,\n",
              "       172,  94,  95,   2,  96,  45,  12,   1,  11,  14, 173,  89,  97,\n",
              "        12,   1,  11,   2, 174,  98,  45,   3,   2,   9,   5, 175,  99,\n",
              "         1,  37, 176, 177,  38,   1,  37,  38,   2,   5, 178, 179,   4,\n",
              "       180,   4, 181, 182,  47,   7,  17,   1,  11,  57,  95,  42,   2,\n",
              "         3,  19,   2,  58,  58, 100,  13,   3,  35, 101,   1, 102,  13,\n",
              "         3,   2,  22,  59, 183, 103,  20,  59, 184,   8,  59, 185,  60,\n",
              "       104,  25,   2, 186, 103,  20, 187,  60, 104, 188,  33,   1, 189,\n",
              "       102, 190,   9, 191,   3,   2,  61, 192,  97,  12,  21,   7,  35,\n",
              "        48, 193,  58, 194,  22,  42,   1, 105,   2,  19, 195, 196,  26,\n",
              "        22,  27, 197,   1, 198,   4,  21,   7,  92,   5, 199, 200, 201,\n",
              "       202, 106,  20, 203, 107,  13,  21, 204, 205,  98, 106,  20,  22,\n",
              "        90, 107,  13,   3,  16,  17,   1,  11,   9,   5, 206, 207, 208,\n",
              "         1,  11,   9,   1, 109,  55,  14,  17,   2,  78, 209,   6,   1,\n",
              "        11,   2,  34,   9,   1, 109,  14,  17,   2,  39, 210, 211,   8,\n",
              "         1,  43,   4,   1,  54,  16,   1,  94,  13,  62,   3,  43,   2,\n",
              "       212, 213,  60, 214,   1, 215,  20, 216, 217,  23,  16,  17,   2,\n",
              "        15,  64,   3,  26,  65,   5, 218,  22,   3,  12,  49,  66, 110,\n",
              "        67,   1, 111, 112, 113,  35, 219, 111,   8, 220,  68,   4,  14,\n",
              "       105,   6,   8, 221, 114,   4,  14,  10,  55, 222, 223,   1, 113,\n",
              "         2, 224, 225,  66,  40, 226, 227,   5,  69,  28,  70,   5,  91,\n",
              "       228, 115,  50,   3,   5,  69,  28,   2,  27,   9,  62,   1,  29,\n",
              "       229,  34, 230,  20, 231,   9,  17,   4,   1, 116,  25,   2,  49,\n",
              "       117,   1,  29,  70,  56, 118,   4,  28, 232,  71,   8,  41,  46,\n",
              "       233, 119,  25, 234, 235, 236,   1, 237, 238,  30,  36,  29,   9,\n",
              "       239, 240, 119,   1, 241,  28,   8,   3,  30,  36, 242,   5, 243,\n",
              "       244,  69,  41,   4,   1,  24,  18,   9, 120,   1,  29,  72,  46,\n",
              "        88, 245,  13, 246, 247, 120,  36,  26,  71,   7, 248,  68,   4,\n",
              "         3,   1,  29,  39,  26, 249, 121,   7, 250, 251,  12,   1,  71,\n",
              "         6,  23, 121,  13,  30,  36,  15,  26,  65, 252,  30, 253,  22,\n",
              "         3,  48,  65,   7,   1,  24,  18,   2,  22,  73, 254, 255,   6,\n",
              "        27, 256,  51,  52, 257,  56,  12,  49,   1,  68, 110,  67,  30,\n",
              "        36,   6,  67, 258,  14, 259,  23,  66, 260,   7,   3, 122,  48,\n",
              "        51,  74, 117,   4, 261, 262,  19,  74,  13,  21, 123,  74, 263,\n",
              "       264,   5, 100, 265, 266,   4, 124,  51, 125, 267,   6,  23, 268,\n",
              "       269,  40,  72,   4, 270, 271,   4, 126, 124,  51, 272, 115,  19,\n",
              "        52,  40,  72,   4,   5, 126, 273, 125,  28,  26,  39, 274, 275,\n",
              "         7,  14,  10,  40,  34,  19,  23,  10, 108,  10,   4,   1,  31,\n",
              "        32, 276, 127,  27, 128, 129, 277,   1,  16,  52,  17,  14, 114,\n",
              "        44,  10, 278,  61, 279,   7,  52, 280,  34, 127,  27, 128, 129,\n",
              "         8,   3, 281, 282, 283,  50, 284,  85,  70, 285,  17, 286,   3,\n",
              "         1,  44,  10,   4,   3,  39, 130,  81,  53,  33,  23,  10, 123,\n",
              "        10, 130,  19, 287, 288, 131, 289, 290,  14,  10,   6,  23,  10,\n",
              "         9,   1,  31,  32,   2,   7,  25, 291,   7,  50, 292,  73,   4,\n",
              "        14,  10, 293, 294, 295,  73,  44, 296, 132, 297,  61,  35, 101,\n",
              "         7,  50,  27,  87,   3, 298,  53,  33, 299,  10, 300,   1,  41,\n",
              "         4,   3,   6,  46,  10,  30,  36,   2, 301,  13,   8,  41,  47,\n",
              "       302,   9,   1,  37,  38,  27,   4, 303,  47,   2,  99, 304, 305,\n",
              "        62,   2,  84,   8, 306, 307,  96, 133, 308,   6,  53,  33,   5,\n",
              "       309, 133,  57,   3, 310,   2,  15,  64,   3,  16,   2,   5, 311,\n",
              "       312,   6,   5,  80, 313,   4,  15,  29,  48, 314,  86,  54,  16,\n",
              "         9,   1,  31,  32,  15, 315,   8, 316, 317, 318,  63, 319, 320,\n",
              "        31,  32, 134,   6, 321,   2, 322, 135,  57,  21,  42,  40,   1,\n",
              "       323,   8, 135,  13,  21,  49,  37,  38,  47,  19,   3, 122, 324,\n",
              "        35, 325,  53,  22,  63,  16, 134,  26, 326, 327,   4, 328,   8,\n",
              "        41,  16,   6,  23, 132,   9, 112, 329, 330,  29, 331,   6, 332,\n",
              "        93,  15, 333,   5, 334, 335,  28,   8, 336, 337,  20, 338,  12,\n",
              "       131, 116,   8,  21, 339, 118,   4,  28, 340, 341, 342, 343,   4,\n",
              "         1, 344,   6, 345, 346,   4,   1,  31,  32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6_Cbaf6LI4S",
        "outputId": "d2fbf2ca-9370-45cb-8556-6dc4b1c8e0a1"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(906, 119)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QJJCVWxMcpy",
        "outputId": "f099e2a4-19ae-480a-d54c-f222a5656416"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(906,)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "PXPZpr5NL9hG"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftevvvBXMXxp",
        "outputId": "e0331ca1-c539-41c3-f627-fdee249e5057"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(906, 347)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input"
      ],
      "metadata": {
        "id": "ETBbTdFhMY8Z"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(56,)),\n",
        "    Embedding(input_dim=347, output_dim=100),\n",
        "    LSTM(150),\n",
        "    Dense(347, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "b-hi1J26PXiB",
        "outputId": "04e8f8ab-0c4f-4f5c-8caf-3ec9682d6b8a"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_11 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m34,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m150,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m347\u001b[0m)                 │          \u001b[38;5;34m52,397\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">347</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">52,397</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m237,697\u001b[0m (928.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">237,697</span> (928.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m237,697\u001b[0m (928.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">237,697</span> (928.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='RMSProp',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MHQ5TmIkOgTK"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs = 110)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NCZ_6otOxs9",
        "outputId": "fb629185-92fe-4ac0-96c6-d3bbeaa32ada"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 237ms/step - accuracy: 0.0720 - loss: 5.2615\n",
            "Epoch 2/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - accuracy: 0.0694 - loss: 5.2542\n",
            "Epoch 3/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - accuracy: 0.0545 - loss: 5.2617\n",
            "Epoch 4/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - accuracy: 0.0641 - loss: 5.1494\n",
            "Epoch 5/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.0623 - loss: 5.2181\n",
            "Epoch 6/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - accuracy: 0.0559 - loss: 5.1993\n",
            "Epoch 7/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 236ms/step - accuracy: 0.0742 - loss: 5.1071\n",
            "Epoch 8/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - accuracy: 0.0849 - loss: 5.0903\n",
            "Epoch 9/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - accuracy: 0.0544 - loss: 5.1155\n",
            "Epoch 10/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - accuracy: 0.0710 - loss: 4.9195\n",
            "Epoch 11/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.0770 - loss: 4.8134\n",
            "Epoch 12/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - accuracy: 0.0810 - loss: 4.7468\n",
            "Epoch 13/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 240ms/step - accuracy: 0.0842 - loss: 4.8080\n",
            "Epoch 14/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 178ms/step - accuracy: 0.1070 - loss: 4.5800\n",
            "Epoch 15/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 237ms/step - accuracy: 0.1369 - loss: 4.3936\n",
            "Epoch 16/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.1194 - loss: 4.4145\n",
            "Epoch 17/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.1267 - loss: 4.2563\n",
            "Epoch 18/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 219ms/step - accuracy: 0.1547 - loss: 4.1309\n",
            "Epoch 19/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 240ms/step - accuracy: 0.1536 - loss: 4.0487\n",
            "Epoch 20/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - accuracy: 0.1753 - loss: 3.9690\n",
            "Epoch 21/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 179ms/step - accuracy: 0.1887 - loss: 3.7748\n",
            "Epoch 22/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 237ms/step - accuracy: 0.2066 - loss: 3.5948\n",
            "Epoch 23/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - accuracy: 0.2063 - loss: 3.5488\n",
            "Epoch 24/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 243ms/step - accuracy: 0.2276 - loss: 3.4095\n",
            "Epoch 25/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.2351 - loss: 3.3594\n",
            "Epoch 26/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - accuracy: 0.2394 - loss: 3.2464\n",
            "Epoch 27/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 182ms/step - accuracy: 0.2756 - loss: 3.1427\n",
            "Epoch 28/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.2916 - loss: 3.0017\n",
            "Epoch 29/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.3071 - loss: 2.9130\n",
            "Epoch 30/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - accuracy: 0.3541 - loss: 2.8149\n",
            "Epoch 31/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 232ms/step - accuracy: 0.3604 - loss: 2.7408\n",
            "Epoch 32/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 186ms/step - accuracy: 0.3676 - loss: 2.6594\n",
            "Epoch 33/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 180ms/step - accuracy: 0.3824 - loss: 2.5617\n",
            "Epoch 34/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.4510 - loss: 2.4268\n",
            "Epoch 35/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 187ms/step - accuracy: 0.4415 - loss: 2.3836\n",
            "Epoch 36/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.4380 - loss: 2.3299\n",
            "Epoch 37/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 242ms/step - accuracy: 0.4859 - loss: 2.2090\n",
            "Epoch 38/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.4813 - loss: 2.1913\n",
            "Epoch 39/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 180ms/step - accuracy: 0.5479 - loss: 2.0524\n",
            "Epoch 40/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 228ms/step - accuracy: 0.5368 - loss: 2.0415\n",
            "Epoch 41/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 241ms/step - accuracy: 0.5640 - loss: 1.9406\n",
            "Epoch 42/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 180ms/step - accuracy: 0.5792 - loss: 1.8766\n",
            "Epoch 43/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.6214 - loss: 1.7626\n",
            "Epoch 44/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 189ms/step - accuracy: 0.6423 - loss: 1.7015\n",
            "Epoch 45/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 175ms/step - accuracy: 0.6545 - loss: 1.6687\n",
            "Epoch 46/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 241ms/step - accuracy: 0.7240 - loss: 1.5913\n",
            "Epoch 47/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - accuracy: 0.7245 - loss: 1.4971\n",
            "Epoch 48/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.6963 - loss: 1.4706\n",
            "Epoch 49/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.7655 - loss: 1.4130\n",
            "Epoch 50/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - accuracy: 0.7877 - loss: 1.3513\n",
            "Epoch 51/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.7996 - loss: 1.3008\n",
            "Epoch 52/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - accuracy: 0.8290 - loss: 1.2669\n",
            "Epoch 53/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 219ms/step - accuracy: 0.8323 - loss: 1.1698\n",
            "Epoch 54/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 234ms/step - accuracy: 0.8468 - loss: 1.1476\n",
            "Epoch 55/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.8510 - loss: 1.1108\n",
            "Epoch 56/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 206ms/step - accuracy: 0.8846 - loss: 1.0224\n",
            "Epoch 57/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 241ms/step - accuracy: 0.9005 - loss: 0.9935\n",
            "Epoch 58/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 178ms/step - accuracy: 0.9106 - loss: 0.9170\n",
            "Epoch 59/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 180ms/step - accuracy: 0.9153 - loss: 0.9217\n",
            "Epoch 60/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 236ms/step - accuracy: 0.9348 - loss: 0.8032\n",
            "Epoch 61/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - accuracy: 0.9371 - loss: 0.8471\n",
            "Epoch 62/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.9260 - loss: 0.7990\n",
            "Epoch 63/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.9531 - loss: 0.7318\n",
            "Epoch 64/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - accuracy: 0.9446 - loss: 0.7275\n",
            "Epoch 65/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - accuracy: 0.9538 - loss: 0.6480\n",
            "Epoch 66/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9551 - loss: 0.6613\n",
            "Epoch 67/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 179ms/step - accuracy: 0.9623 - loss: 0.6098\n",
            "Epoch 68/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.9719 - loss: 0.5897\n",
            "Epoch 69/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - accuracy: 0.9693 - loss: 0.5413\n",
            "Epoch 70/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 244ms/step - accuracy: 0.9782 - loss: 0.5254\n",
            "Epoch 71/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9747 - loss: 0.4999\n",
            "Epoch 72/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 0.9870 - loss: 0.4654\n",
            "Epoch 73/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 241ms/step - accuracy: 0.9801 - loss: 0.4503\n",
            "Epoch 74/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 178ms/step - accuracy: 0.9897 - loss: 0.4258\n",
            "Epoch 75/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 180ms/step - accuracy: 0.9904 - loss: 0.3890\n",
            "Epoch 76/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.9879 - loss: 0.3842\n",
            "Epoch 77/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 207ms/step - accuracy: 0.9892 - loss: 0.3513\n",
            "Epoch 78/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9933 - loss: 0.3406\n",
            "Epoch 79/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - accuracy: 0.9901 - loss: 0.3234\n",
            "Epoch 80/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - accuracy: 0.9887 - loss: 0.3126\n",
            "Epoch 81/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - accuracy: 0.9905 - loss: 0.2910\n",
            "Epoch 82/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 237ms/step - accuracy: 0.9896 - loss: 0.2807\n",
            "Epoch 83/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 177ms/step - accuracy: 0.9956 - loss: 0.2540\n",
            "Epoch 84/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - accuracy: 0.9953 - loss: 0.2395\n",
            "Epoch 85/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 175ms/step - accuracy: 0.9919 - loss: 0.2344\n",
            "Epoch 86/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.9908 - loss: 0.2284\n",
            "Epoch 87/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9917 - loss: 0.1972\n",
            "Epoch 88/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - accuracy: 0.9957 - loss: 0.1868\n",
            "Epoch 89/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9947 - loss: 0.1776\n",
            "Epoch 90/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.9949 - loss: 0.1813\n",
            "Epoch 91/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - accuracy: 0.9916 - loss: 0.1694\n",
            "Epoch 92/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 181ms/step - accuracy: 0.9914 - loss: 0.1563\n",
            "Epoch 93/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.9945 - loss: 0.1438\n",
            "Epoch 94/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 195ms/step - accuracy: 0.9929 - loss: 0.1364\n",
            "Epoch 95/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 305ms/step - accuracy: 0.9955 - loss: 0.1340\n",
            "Epoch 96/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.9956 - loss: 0.1244\n",
            "Epoch 97/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - accuracy: 0.9897 - loss: 0.1182\n",
            "Epoch 98/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 182ms/step - accuracy: 0.9946 - loss: 0.1030\n",
            "Epoch 99/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 180ms/step - accuracy: 0.9918 - loss: 0.1170\n",
            "Epoch 100/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 182ms/step - accuracy: 0.9929 - loss: 0.0950\n",
            "Epoch 101/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 195ms/step - accuracy: 0.9929 - loss: 0.0935\n",
            "Epoch 102/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - accuracy: 0.9907 - loss: 0.0920\n",
            "Epoch 103/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.9859 - loss: 0.0974\n",
            "Epoch 104/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - accuracy: 0.9943 - loss: 0.0782\n",
            "Epoch 105/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 180ms/step - accuracy: 0.9906 - loss: 0.0819\n",
            "Epoch 106/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 182ms/step - accuracy: 0.9928 - loss: 0.0727\n",
            "Epoch 107/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - accuracy: 0.9965 - loss: 0.0677\n",
            "Epoch 108/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.9950 - loss: 0.0605\n",
            "Epoch 109/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - accuracy: 0.9940 - loss: 0.0576\n",
            "Epoch 110/110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 182ms/step - accuracy: 0.9917 - loss: 0.0601\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a3cb0d19b70>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "lkSuZhWMjiqT"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"On average, Pluto is a distance of\"\n",
        "#text = \"NASA\"\n",
        "for i in range(10):\n",
        "  tokenized_output_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  padded_text = pad_sequences([tokenized_output_text], maxlen=120, padding='pre')\n",
        "  pos = np.argmax(model.predict(padded_text)[0])\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "id": "ZV0JnkJ-jgpW",
        "outputId": "cef50b0b-a568-4f77-b2eb-6ad0067be3e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "On average, Pluto is a distance of 39\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "On average, Pluto is a distance of 39 5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au from\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au from the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au from the sun\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au from the sun that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=110, validation_split=0.2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "qXhW0CKGhG80",
        "outputId": "24ce7298-33ba-4bda-ed97-df7c51a2ef33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.9929 - loss: 0.0584 - val_accuracy: 0.9945 - val_loss: 0.0538\n",
            "Epoch 2/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 275ms/step - accuracy: 0.9880 - loss: 0.0571 - val_accuracy: 0.9945 - val_loss: 0.0566\n",
            "Epoch 3/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 199ms/step - accuracy: 0.9953 - loss: 0.0449 - val_accuracy: 0.9945 - val_loss: 0.0622\n",
            "Epoch 4/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9928 - loss: 0.0518 - val_accuracy: 0.9945 - val_loss: 0.0651\n",
            "Epoch 5/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.9957 - loss: 0.0474 - val_accuracy: 0.9945 - val_loss: 0.0698\n",
            "Epoch 6/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - accuracy: 0.9948 - loss: 0.0442 - val_accuracy: 0.9945 - val_loss: 0.0716\n",
            "Epoch 7/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step - accuracy: 0.9886 - loss: 0.0445 - val_accuracy: 0.9945 - val_loss: 0.0737\n",
            "Epoch 8/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 197ms/step - accuracy: 0.9889 - loss: 0.0434 - val_accuracy: 0.9945 - val_loss: 0.0772\n",
            "Epoch 9/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - accuracy: 0.9943 - loss: 0.0368 - val_accuracy: 0.9945 - val_loss: 0.0784\n",
            "Epoch 10/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 197ms/step - accuracy: 0.9951 - loss: 0.0379 - val_accuracy: 0.9945 - val_loss: 0.0819\n",
            "Epoch 11/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - accuracy: 0.9929 - loss: 0.0334 - val_accuracy: 0.9945 - val_loss: 0.0849\n",
            "Epoch 12/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 258ms/step - accuracy: 0.9968 - loss: 0.0317 - val_accuracy: 0.9945 - val_loss: 0.0857\n",
            "Epoch 13/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 196ms/step - accuracy: 0.9890 - loss: 0.0363 - val_accuracy: 0.9945 - val_loss: 0.0881\n",
            "Epoch 14/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - accuracy: 0.9929 - loss: 0.0293 - val_accuracy: 0.9945 - val_loss: 0.0901\n",
            "Epoch 15/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.9954 - loss: 0.0273 - val_accuracy: 0.9890 - val_loss: 0.0926\n",
            "Epoch 16/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.9934 - loss: 0.0292 - val_accuracy: 0.9890 - val_loss: 0.0952\n",
            "Epoch 17/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.9978 - loss: 0.0227 - val_accuracy: 0.9945 - val_loss: 0.0957\n",
            "Epoch 18/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 290ms/step - accuracy: 0.9923 - loss: 0.0252 - val_accuracy: 0.9945 - val_loss: 0.0998\n",
            "Epoch 19/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 198ms/step - accuracy: 0.9937 - loss: 0.0284 - val_accuracy: 0.9945 - val_loss: 0.0980\n",
            "Epoch 20/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9956 - loss: 0.0251 - val_accuracy: 0.9890 - val_loss: 0.0997\n",
            "Epoch 21/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.9974 - loss: 0.0196 - val_accuracy: 0.9945 - val_loss: 0.1008\n",
            "Epoch 22/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.9893 - loss: 0.0273 - val_accuracy: 0.9945 - val_loss: 0.1044\n",
            "Epoch 23/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 197ms/step - accuracy: 0.9928 - loss: 0.0304 - val_accuracy: 0.9945 - val_loss: 0.1074\n",
            "Epoch 24/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9946 - loss: 0.0219 - val_accuracy: 0.9890 - val_loss: 0.1116\n",
            "Epoch 25/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.9939 - loss: 0.0230 - val_accuracy: 0.9945 - val_loss: 0.1085\n",
            "Epoch 26/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - accuracy: 0.9975 - loss: 0.0169 - val_accuracy: 0.9945 - val_loss: 0.1103\n",
            "Epoch 27/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.9962 - loss: 0.0181 - val_accuracy: 0.9945 - val_loss: 0.1128\n",
            "Epoch 28/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 196ms/step - accuracy: 0.9941 - loss: 0.0225 - val_accuracy: 0.9945 - val_loss: 0.1126\n",
            "Epoch 29/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.9907 - loss: 0.0240 - val_accuracy: 0.9945 - val_loss: 0.1143\n",
            "Epoch 30/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.9955 - loss: 0.0150 - val_accuracy: 0.9945 - val_loss: 0.1159\n",
            "Epoch 31/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.9915 - loss: 0.0228 - val_accuracy: 0.9945 - val_loss: 0.1176\n",
            "Epoch 32/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 198ms/step - accuracy: 0.9939 - loss: 0.0193 - val_accuracy: 0.9945 - val_loss: 0.1197\n",
            "Epoch 33/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9875 - loss: 0.0301 - val_accuracy: 0.9945 - val_loss: 0.1221\n",
            "Epoch 34/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.9896 - loss: 0.0225 - val_accuracy: 0.9945 - val_loss: 0.1227\n",
            "Epoch 35/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 240ms/step - accuracy: 0.9938 - loss: 0.0212 - val_accuracy: 0.9890 - val_loss: 0.1269\n",
            "Epoch 36/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.9943 - loss: 0.0204 - val_accuracy: 0.9945 - val_loss: 0.1249\n",
            "Epoch 37/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 278ms/step - accuracy: 0.9926 - loss: 0.0197 - val_accuracy: 0.9890 - val_loss: 0.1317\n",
            "Epoch 38/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.9952 - loss: 0.0168 - val_accuracy: 0.9945 - val_loss: 0.1298\n",
            "Epoch 39/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.9931 - loss: 0.0238 - val_accuracy: 0.9890 - val_loss: 0.1325\n",
            "Epoch 40/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 196ms/step - accuracy: 0.9932 - loss: 0.0184 - val_accuracy: 0.9945 - val_loss: 0.1338\n",
            "Epoch 41/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - accuracy: 0.9924 - loss: 0.0166 - val_accuracy: 0.9945 - val_loss: 0.1348\n",
            "Epoch 42/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 197ms/step - accuracy: 0.9920 - loss: 0.0179 - val_accuracy: 0.9945 - val_loss: 0.1345\n",
            "Epoch 43/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9937 - loss: 0.0183 - val_accuracy: 0.9945 - val_loss: 0.1362\n",
            "Epoch 44/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.9963 - loss: 0.0186 - val_accuracy: 0.9945 - val_loss: 0.1380\n",
            "Epoch 45/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 272ms/step - accuracy: 0.9946 - loss: 0.0208 - val_accuracy: 0.9890 - val_loss: 0.1403\n",
            "Epoch 46/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 197ms/step - accuracy: 0.9977 - loss: 0.0124 - val_accuracy: 0.9890 - val_loss: 0.1409\n",
            "Epoch 47/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.9947 - loss: 0.0138 - val_accuracy: 0.9945 - val_loss: 0.1439\n",
            "Epoch 48/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - accuracy: 0.9879 - loss: 0.0217 - val_accuracy: 0.9945 - val_loss: 0.1444\n",
            "Epoch 49/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.9967 - loss: 0.0105 - val_accuracy: 0.9945 - val_loss: 0.1440\n",
            "Epoch 50/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.9952 - loss: 0.0121 - val_accuracy: 0.9945 - val_loss: 0.1456\n",
            "Epoch 51/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 273ms/step - accuracy: 0.9935 - loss: 0.0190 - val_accuracy: 0.9945 - val_loss: 0.1479\n",
            "Epoch 52/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 196ms/step - accuracy: 0.9901 - loss: 0.0229 - val_accuracy: 0.9945 - val_loss: 0.1506\n",
            "Epoch 53/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9901 - loss: 0.0171 - val_accuracy: 0.9945 - val_loss: 0.1514\n",
            "Epoch 54/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.9961 - loss: 0.0126 - val_accuracy: 0.9945 - val_loss: 0.1532\n",
            "Epoch 55/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 268ms/step - accuracy: 0.9973 - loss: 0.0106 - val_accuracy: 0.9945 - val_loss: 0.1546\n",
            "Epoch 56/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 202ms/step - accuracy: 0.9899 - loss: 0.0166 - val_accuracy: 0.9945 - val_loss: 0.1558\n",
            "Epoch 57/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - accuracy: 0.9975 - loss: 0.0109 - val_accuracy: 0.9945 - val_loss: 0.1578\n",
            "Epoch 58/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 272ms/step - accuracy: 0.9928 - loss: 0.0154 - val_accuracy: 0.9945 - val_loss: 0.1578\n",
            "Epoch 59/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 0.9914 - loss: 0.0194 - val_accuracy: 0.9945 - val_loss: 0.1588\n",
            "Epoch 60/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 245ms/step - accuracy: 0.9928 - loss: 0.0155 - val_accuracy: 0.9945 - val_loss: 0.1609\n",
            "Epoch 61/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.9960 - loss: 0.0135 - val_accuracy: 0.9945 - val_loss: 0.1624\n",
            "Epoch 62/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 198ms/step - accuracy: 0.9966 - loss: 0.0138 - val_accuracy: 0.9945 - val_loss: 0.1639\n",
            "Epoch 63/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 272ms/step - accuracy: 0.9893 - loss: 0.0158 - val_accuracy: 0.9945 - val_loss: 0.1645\n",
            "Epoch 64/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.9914 - loss: 0.0165 - val_accuracy: 0.9945 - val_loss: 0.1668\n",
            "Epoch 65/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.9909 - loss: 0.0180 - val_accuracy: 0.9945 - val_loss: 0.1672\n",
            "Epoch 66/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step - accuracy: 0.9892 - loss: 0.0183 - val_accuracy: 0.9945 - val_loss: 0.1682\n",
            "Epoch 67/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 194ms/step - accuracy: 0.9939 - loss: 0.0155 - val_accuracy: 0.9945 - val_loss: 0.1712\n",
            "Epoch 68/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 272ms/step - accuracy: 0.9909 - loss: 0.0158 - val_accuracy: 0.9945 - val_loss: 0.1714\n",
            "Epoch 69/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - accuracy: 0.9946 - loss: 0.0149 - val_accuracy: 0.9945 - val_loss: 0.1729\n",
            "Epoch 70/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.9913 - loss: 0.0186 - val_accuracy: 0.9945 - val_loss: 0.1748\n",
            "Epoch 71/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 198ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.9945 - val_loss: 0.1757\n",
            "Epoch 72/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9954 - loss: 0.0118 - val_accuracy: 0.9945 - val_loss: 0.1778\n",
            "Epoch 73/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - accuracy: 0.9958 - loss: 0.0113 - val_accuracy: 0.9945 - val_loss: 0.1783\n",
            "Epoch 74/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 245ms/step - accuracy: 0.9944 - loss: 0.0127 - val_accuracy: 0.9945 - val_loss: 0.1801\n",
            "Epoch 75/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - accuracy: 0.9958 - loss: 0.0120 - val_accuracy: 0.9945 - val_loss: 0.1818\n",
            "Epoch 76/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9946 - loss: 0.0110 - val_accuracy: 0.9945 - val_loss: 0.1845\n",
            "Epoch 77/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 197ms/step - accuracy: 0.9980 - loss: 0.0103 - val_accuracy: 0.9945 - val_loss: 0.1854\n",
            "Epoch 78/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.9950 - loss: 0.0166 - val_accuracy: 0.9890 - val_loss: 0.1879\n",
            "Epoch 79/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.9974 - loss: 0.0151 - val_accuracy: 0.9945 - val_loss: 0.1872\n",
            "Epoch 80/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.9954 - loss: 0.0112 - val_accuracy: 0.9890 - val_loss: 0.1892\n",
            "Epoch 81/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 275ms/step - accuracy: 0.9933 - loss: 0.0153 - val_accuracy: 0.9945 - val_loss: 0.1888\n",
            "Epoch 82/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 196ms/step - accuracy: 0.9938 - loss: 0.0147 - val_accuracy: 0.9890 - val_loss: 0.1917\n",
            "Epoch 83/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 275ms/step - accuracy: 0.9965 - loss: 0.0104 - val_accuracy: 0.9890 - val_loss: 0.1921\n",
            "Epoch 84/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - accuracy: 0.9938 - loss: 0.0163 - val_accuracy: 0.9890 - val_loss: 0.1945\n",
            "Epoch 85/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.9967 - loss: 0.0132 - val_accuracy: 0.9890 - val_loss: 0.1975\n",
            "Epoch 86/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.9918 - loss: 0.0174 - val_accuracy: 0.9890 - val_loss: 0.1959\n",
            "Epoch 87/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.9963 - loss: 0.0121 - val_accuracy: 0.9890 - val_loss: 0.1993\n",
            "Epoch 88/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.9935 - loss: 0.0170 - val_accuracy: 0.9835 - val_loss: 0.2019\n",
            "Epoch 89/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.9907 - loss: 0.0176 - val_accuracy: 0.9835 - val_loss: 0.2024\n",
            "Epoch 90/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.9949 - loss: 0.0174 - val_accuracy: 0.9835 - val_loss: 0.2037\n",
            "Epoch 91/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - accuracy: 0.9941 - loss: 0.0127 - val_accuracy: 0.9835 - val_loss: 0.2039\n",
            "Epoch 92/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 197ms/step - accuracy: 0.9955 - loss: 0.0122 - val_accuracy: 0.9725 - val_loss: 0.2061\n",
            "Epoch 93/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9975 - loss: 0.0145 - val_accuracy: 0.9780 - val_loss: 0.2072\n",
            "Epoch 94/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 202ms/step - accuracy: 0.9943 - loss: 0.0108 - val_accuracy: 0.9780 - val_loss: 0.2087\n",
            "Epoch 95/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 243ms/step - accuracy: 0.9961 - loss: 0.0092 - val_accuracy: 0.9780 - val_loss: 0.2096\n",
            "Epoch 96/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.9921 - loss: 0.0120 - val_accuracy: 0.9780 - val_loss: 0.2113\n",
            "Epoch 97/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 274ms/step - accuracy: 0.9904 - loss: 0.0160 - val_accuracy: 0.9780 - val_loss: 0.2149\n",
            "Epoch 98/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.9884 - loss: 0.0158 - val_accuracy: 0.9780 - val_loss: 0.2145\n",
            "Epoch 99/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.9919 - loss: 0.0155 - val_accuracy: 0.9780 - val_loss: 0.2147\n",
            "Epoch 100/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.9947 - loss: 0.0126 - val_accuracy: 0.9780 - val_loss: 0.2154\n",
            "Epoch 101/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.9940 - loss: 0.0205 - val_accuracy: 0.9780 - val_loss: 0.2178\n",
            "Epoch 102/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 196ms/step - accuracy: 0.9961 - loss: 0.0112 - val_accuracy: 0.9780 - val_loss: 0.2175\n",
            "Epoch 103/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.9914 - loss: 0.0163 - val_accuracy: 0.9780 - val_loss: 0.2209\n",
            "Epoch 104/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.9937 - loss: 0.0111 - val_accuracy: 0.9780 - val_loss: 0.2223\n",
            "Epoch 105/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.9956 - loss: 0.0083 - val_accuracy: 0.9780 - val_loss: 0.2229\n",
            "Epoch 106/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - accuracy: 0.9949 - loss: 0.0088 - val_accuracy: 0.9780 - val_loss: 0.2233\n",
            "Epoch 107/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 197ms/step - accuracy: 0.9911 - loss: 0.0149 - val_accuracy: 0.9780 - val_loss: 0.2260\n",
            "Epoch 108/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 273ms/step - accuracy: 0.9931 - loss: 0.0145 - val_accuracy: 0.9780 - val_loss: 0.2277\n",
            "Epoch 109/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.9902 - loss: 0.0202 - val_accuracy: 0.9780 - val_loss: 0.2293\n",
            "Epoch 110/110\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.9841 - loss: 0.0274 - val_accuracy: 0.9725 - val_loss: 0.2311\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a3cb0c4d540>"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "JyUs_kixYAAU"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text = \"On average, Pluto is a distance of\"\n",
        "text = \"On average, Pluto is a distance\"\n",
        "for i in range(10):\n",
        "  tokenized_output_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  padded_text = pad_sequences([tokenized_output_text], maxlen=120, padding='pre')\n",
        "  pos = np.argmax(model.predict(padded_text)[0])\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfuRrsCpRMrN",
        "outputId": "2d4ba656-4029-491a-b95e-15d141b04c59"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "On average, Pluto is a distance of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "On average, Pluto is a distance of 39\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "On average, Pluto is a distance of 39 5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au from\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au from the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "On average, Pluto is a distance of 39 5 astronomical units or au from the sun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeCimsogWWRV",
        "outputId": "3ced2cc1-fef1-45d7-d103-209638e43e0b"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'is': 2,\n",
              " 'pluto': 3,\n",
              " 'of': 4,\n",
              " 'a': 5,\n",
              " 'and': 6,\n",
              " 'that': 7,\n",
              " 'to': 8,\n",
              " 'in': 9,\n",
              " 'moons': 10,\n",
              " 'sun': 11,\n",
              " 'from': 12,\n",
              " 'on': 13,\n",
              " 'pluto’s': 14,\n",
              " 'nasa': 15,\n",
              " 'planets': 16,\n",
              " 'orbit': 17,\n",
              " 'planet': 18,\n",
              " 'like': 19,\n",
              " 'or': 20,\n",
              " 'earth': 21,\n",
              " 'about': 22,\n",
              " 'other': 23,\n",
              " 'dwarf': 24,\n",
              " 'it': 25,\n",
              " 'has': 26,\n",
              " 'one': 27,\n",
              " 'mission': 28,\n",
              " 'spacecraft': 29,\n",
              " 'new': 30,\n",
              " 'solar': 31,\n",
              " 'system': 32,\n",
              " 'than': 33,\n",
              " 'not': 34,\n",
              " 'scientists': 35,\n",
              " 'horizons': 36,\n",
              " 'kuiper': 37,\n",
              " 'belt': 38,\n",
              " 'also': 39,\n",
              " 'are': 40,\n",
              " 'study': 41,\n",
              " 'what': 42,\n",
              " 'orbits': 43,\n",
              " 'smaller': 44,\n",
              " 'au': 45,\n",
              " 'its': 46,\n",
              " 'objects': 47,\n",
              " 'have': 48,\n",
              " 'studying': 49,\n",
              " 'at': 50,\n",
              " 'ice': 51,\n",
              " 'they': 52,\n",
              " 'more': 53,\n",
              " 'eight': 54,\n",
              " 'but': 55,\n",
              " 'this': 56,\n",
              " 'beyond': 57,\n",
              " 'very': 58,\n",
              " 'minus': 59,\n",
              " 'degrees': 60,\n",
              " 'so': 61,\n",
              " 'which': 62,\n",
              " 'how': 63,\n",
              " 'exploring': 64,\n",
              " 'learned': 65,\n",
              " 'images': 66,\n",
              " 'by': 67,\n",
              " 'pictures': 68,\n",
              " 'flyby': 69,\n",
              " 'for': 70,\n",
              " 'cameras': 71,\n",
              " 'made': 72,\n",
              " 'two': 73,\n",
              " 'volcanoes': 74,\n",
              " 'object': 75,\n",
              " 'same': 76,\n",
              " 'year': 77,\n",
              " 'an': 78,\n",
              " 'after': 79,\n",
              " 'major': 80,\n",
              " 'much': 81,\n",
              " 'because': 82,\n",
              " 'distance': 83,\n",
              " '40': 84,\n",
              " 'times': 85,\n",
              " 'all': 86,\n",
              " 'time': 87,\n",
              " 'closest': 88,\n",
              " 'point': 89,\n",
              " '7': 90,\n",
              " 'close': 91,\n",
              " 'means': 92,\n",
              " 'sometimes': 93,\n",
              " 'path': 94,\n",
              " 'neptune': 95,\n",
              " '30': 96,\n",
              " 'away': 97,\n",
              " '3': 98,\n",
              " 'called': 99,\n",
              " 'cold': 100,\n",
              " 'believe': 101,\n",
              " 'temperature': 102,\n",
              " 'celsius': 103,\n",
              " 'fahrenheit': 104,\n",
              " 'surface': 105,\n",
              " 'kilograms': 106,\n",
              " 'pounds': 107,\n",
              " 'most': 108,\n",
              " 'center': 109,\n",
              " 'taken': 110,\n",
              " 'hubble': 111,\n",
              " 'space': 112,\n",
              " 'telescope': 113,\n",
              " 'four': 114,\n",
              " 'look': 115,\n",
              " 'body': 116,\n",
              " 'instead': 117,\n",
              " 'type': 118,\n",
              " 'as': 119,\n",
              " '2015': 120,\n",
              " 'instruments': 121,\n",
              " 'may': 122,\n",
              " 'these': 123,\n",
              " 'water': 124,\n",
              " 'nitrogen': 125,\n",
              " 'frozen': 126,\n",
              " 'keep': 127,\n",
              " 'face': 128,\n",
              " 'pointed': 129,\n",
              " 'wobble': 130,\n",
              " 'another': 131,\n",
              " 'bodies': 132,\n",
              " 'miles': 133,\n",
              " 'form': 134,\n",
              " 'life': 135,\n",
              " 'trans': 136,\n",
              " 'neptunian': 137,\n",
              " 'clyde': 138,\n",
              " 'tombaugh': 139,\n",
              " 'u': 140,\n",
              " 's': 141,\n",
              " 'astronomer': 142,\n",
              " 'discovered': 143,\n",
              " '1930': 144,\n",
              " 'venetia': 145,\n",
              " 'burney': 146,\n",
              " '11': 147,\n",
              " 'old': 148,\n",
              " 'girl': 149,\n",
              " 'england': 150,\n",
              " 'suggested': 151,\n",
              " 'be': 152,\n",
              " 'named': 153,\n",
              " '“pluto”': 154,\n",
              " 'roman': 155,\n",
              " 'god': 156,\n",
              " 'dead': 157,\n",
              " 'round': 158,\n",
              " 'just': 159,\n",
              " 'moon': 160,\n",
              " 'average': 161,\n",
              " '39': 162,\n",
              " '5': 163,\n",
              " 'astronomical': 164,\n",
              " 'units': 165,\n",
              " 'almost': 166,\n",
              " 'farther': 167,\n",
              " 'elliptical': 168,\n",
              " '29': 169,\n",
              " 'getting': 170,\n",
              " 'crosses': 171,\n",
              " 'neptune’s': 172,\n",
              " 'farthest': 173,\n",
              " '49': 174,\n",
              " 'region': 175,\n",
              " 'ky': 176,\n",
              " 'per': 177,\n",
              " 'large': 178,\n",
              " 'donut': 179,\n",
              " 'thousands': 180,\n",
              " 'small': 181,\n",
              " 'icy': 182,\n",
              " '230': 183,\n",
              " '375': 184,\n",
              " '400': 185,\n",
              " '74': 186,\n",
              " '133': 187,\n",
              " 'colder': 188,\n",
              " 'coldest': 189,\n",
              " 'recorded': 190,\n",
              " 'antarctica': 191,\n",
              " 'far': 192,\n",
              " 'known': 193,\n",
              " 'little': 194,\n",
              " 'until': 195,\n",
              " 'recently': 196,\n",
              " 'fifteenth': 197,\n",
              " 'gravity': 198,\n",
              " 'person': 199,\n",
              " 'who': 200,\n",
              " 'weighs': 201,\n",
              " '45': 202,\n",
              " '100': 203,\n",
              " 'would': 204,\n",
              " 'weigh': 205,\n",
              " 'near': 206,\n",
              " 'circle': 207,\n",
              " 'with': 208,\n",
              " 'ellipse': 209,\n",
              " 'tilted': 210,\n",
              " 'compared': 211,\n",
              " 'angled': 212,\n",
              " '17': 213,\n",
              " 'above': 214,\n",
              " 'line': 215,\n",
              " 'plane': 216,\n",
              " 'where': 217,\n",
              " 'lot': 218,\n",
              " 'used': 219,\n",
              " 'take': 220,\n",
              " 'discover': 221,\n",
              " 'even': 222,\n",
              " 'though': 223,\n",
              " 'powerful': 224,\n",
              " 'hubble’s': 225,\n",
              " 'fuzzy': 226,\n",
              " 'sent': 227,\n",
              " 'up': 228,\n",
              " 'does': 229,\n",
              " 'land': 230,\n",
              " 'stay': 231,\n",
              " 'uses': 232,\n",
              " 'target': 233,\n",
              " 'flies': 234,\n",
              " 'past': 235,\n",
              " 'launched': 236,\n",
              " 'piano': 237,\n",
              " 'sized': 238,\n",
              " 'january': 239,\n",
              " '2006': 240,\n",
              " 'first': 241,\n",
              " 'conducted': 242,\n",
              " 'six': 243,\n",
              " 'month': 244,\n",
              " 'approach': 245,\n",
              " 'july': 246,\n",
              " '14': 247,\n",
              " 'took': 248,\n",
              " 'scientific': 249,\n",
              " 'gathered': 250,\n",
              " 'information': 251,\n",
              " 'many': 252,\n",
              " 'facts': 253,\n",
              " 'thirds': 254,\n",
              " 'rock': 255,\n",
              " 'third': 256,\n",
              " 'concluded': 257,\n",
              " 'measuring': 258,\n",
              " 'density': 259,\n",
              " 'show': 260,\n",
              " 'spewing': 261,\n",
              " 'lava': 262,\n",
              " 'probably': 263,\n",
              " 'emit': 264,\n",
              " 'slushy': 265,\n",
              " 'mixture': 266,\n",
              " 'methane': 267,\n",
              " 'substances': 268,\n",
              " 'mountains': 269,\n",
              " 'giant': 270,\n",
              " 'blocks': 271,\n",
              " 'plains': 272,\n",
              " 'gas': 273,\n",
              " 'shown': 274,\n",
              " 'us': 275,\n",
              " 'always': 276,\n",
              " 'toward': 277,\n",
              " 'spin': 278,\n",
              " 'fast': 279,\n",
              " 'do': 280,\n",
              " 'hydra': 281,\n",
              " 'spins': 282,\n",
              " 'fastest': 283,\n",
              " '89': 284,\n",
              " 'every': 285,\n",
              " 'around': 286,\n",
              " 'spinning': 287,\n",
              " 'tops': 288,\n",
              " 'difference': 289,\n",
              " 'between': 290,\n",
              " 'seems': 291,\n",
              " 'least': 292,\n",
              " 'were': 293,\n",
              " 'formed': 294,\n",
              " 'when': 295,\n",
              " 'rocky': 296,\n",
              " 'merged': 297,\n",
              " 'had': 298,\n",
              " 'five': 299,\n",
              " 'finishing': 300,\n",
              " 'moving': 301,\n",
              " 'deeper': 302,\n",
              " 'those': 303,\n",
              " '2014': 304,\n",
              " 'mu69': 305,\n",
              " '50': 306,\n",
              " 'kilometers': 307,\n",
              " 'wide': 308,\n",
              " 'billion': 309,\n",
              " 'why': 310,\n",
              " 'historic': 311,\n",
              " 'endeavor': 312,\n",
              " 'focus': 313,\n",
              " 'visited': 314,\n",
              " 'seeks': 315,\n",
              " 'answer': 316,\n",
              " 'fundamental': 317,\n",
              " 'questions': 318,\n",
              " 'did': 319,\n",
              " 'our': 320,\n",
              " 'evolve': 321,\n",
              " 'there': 322,\n",
              " 'hazards': 323,\n",
              " 'help': 324,\n",
              " 'learn': 325,\n",
              " 'several': 326,\n",
              " 'types': 327,\n",
              " 'missions': 328,\n",
              " 'flybys': 329,\n",
              " 'orbiting': 330,\n",
              " 'landers': 331,\n",
              " 'rovers': 332,\n",
              " 'conducts': 333,\n",
              " 'sample': 334,\n",
              " 'return': 335,\n",
              " 'bring': 336,\n",
              " 'rocks': 337,\n",
              " 'soil': 338,\n",
              " 'each': 339,\n",
              " 'helps': 340,\n",
              " 'advance': 341,\n",
              " 'human': 342,\n",
              " 'understanding': 343,\n",
              " 'chemical': 344,\n",
              " 'physical': 345,\n",
              " 'history': 346}"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ROPq9yUWgMt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}